{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import ftplib\n",
    "import datetime\n",
    "import requests\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import Point\n",
    "from rasterio.transform import from_origin\n",
    "from netCDF4 import Dataset, num2date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_nc_file = \"../data/row\"\n",
    "path_nc_row = \"../repository/pre-processing/row\"\n",
    "path_modified = \"../repository/pre-processing/result-row\"\n",
    "path_pch_tabular = \"../data/tabular/data_pch_balai_01212025.xlsx\"\n",
    "mask_pulau = \"../data/geojson/pulau.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: ECMWF.0125.202503041200.PREC.nc\n",
      "Download successfully ECMWF.0125.202503041200.PREC.nc\n"
     ]
    }
   ],
   "source": [
    "ftp_host = os.getenv(\"HOST\")\n",
    "ftp_user = os.getenv(\"USER\")\n",
    "ftp_password = os.getenv(\"PASSWORD\")\n",
    "cycle = \"12\"\n",
    "\n",
    "def connect_ftp():\n",
    "    ftp = ftplib.FTP(ftp_host)\n",
    "    ftp.login(ftp_user, ftp_password)\n",
    "    ftp.cwd(\"/\")\n",
    "    return ftp\n",
    "\n",
    "def download_file_from_ftp(ftp, filename):\n",
    "    try:\n",
    "        file_list = ftp.nlst()\n",
    "        if filename in file_list:\n",
    "            local_file_path = os.path.join(path_nc_file, filename)\n",
    "            if not os.path.exists(local_file_path):\n",
    "                with open(local_file_path, \"wb\") as local_file:\n",
    "                    ftp.retrbinary(f\"RETR {filename}\", local_file.write)\n",
    "                print(f\"Download successfully {filename}\")\n",
    "            else:\n",
    "                print(f\"File {filename} is available\")\n",
    "            return local_file_path\n",
    "    except Exception:\n",
    "        print(\"File is corrupted, and there is nothing that can be done.\")\n",
    "        return None\n",
    "\n",
    "def download_latest_file_from_ftp(ftp):\n",
    "    file_list = ftp.nlst()\n",
    "    if file_list:\n",
    "        latest_file = sorted(file_list)[-1]\n",
    "        return download_file_from_ftp(ftp, latest_file)\n",
    "    return None\n",
    "\n",
    "today = datetime.date.today() - datetime.timedelta(days=1)\n",
    "filename = f\"ECMWF.0125.{today.strftime('%Y%m%d')}{cycle}00.PREC.nc\"\n",
    "print(\"Downloading:\", filename)\n",
    "\n",
    "ftp = connect_ftp()\n",
    "if ftp:\n",
    "    local_file_path = download_file_from_ftp(ftp, filename) or download_latest_file_from_ftp(ftp)\n",
    "    ftp.quit()\n",
    "else:\n",
    "    print(\"Cannot connect to FTP server\")\n",
    "\n",
    "if local_file_path is None:\n",
    "    print(\"File is currently unavailable for download.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-05 16:00:00 WIB\n",
      "2025-03-06 16:00:00 WIB\n",
      "True\n",
      "<xarray.Dataset> Size: 43MB\n",
      "Dimensions:  (lat: 185, lon: 449, lev: 1, time: 65)\n",
      "Coordinates:\n",
      "  * lat      (lat) float64 1kB 9.0 8.875 8.75 8.625 ... -13.75 -13.88 -14.0\n",
      "  * lon      (lon) float64 4kB 92.0 92.12 92.25 92.38 ... 147.8 147.9 148.0\n",
      "  * lev      (lev) float64 8B 1.013e+03\n",
      "  * time     (time) datetime64[ns] 520B 2025-03-04T19:00:00 ... 2025-03-14T19...\n",
      "Data variables:\n",
      "    tp       (time, lev, lat, lon) float64 43MB 0.0 0.0 0.0 ... 0.6562 0.9375\n",
      "Attributes:\n",
      "    title:        IFS Precipitation\n",
      "    conventions:  COARDS\n",
      "    datatype:     Grid\n",
      "    cachesize:    626240 bytes\n"
     ]
    }
   ],
   "source": [
    "data = Dataset(local_file_path)\n",
    "\n",
    "lat = data.variables['lat'][:]\n",
    "lon = data.variables['lon'][:]\n",
    "prec = data.variables['tp'][:,0,:,:]\n",
    "time = data.variables['time'][:]\n",
    "\n",
    "dates = num2date(time, data.variables['time'].units)\n",
    "print((dates[7]+datetime.timedelta(hours=7)).strftime('%Y-%m-%d %H:%M:%S WIB'))\n",
    "print((dates[15]+datetime.timedelta(hours=7)).strftime('%Y-%m-%d %H:%M:%S WIB'))\n",
    "\n",
    "xrain = prec\n",
    "print(np.array_equal(xrain,prec))\n",
    "\n",
    "for time in range (len(dates)):\n",
    "    for lati in range(len(lat)) :\n",
    "        for loni in range (len(lon)) :\n",
    "            if (time<=0) :\n",
    "                if (xrain[time,lati,loni]<=0) :\n",
    "                    xrain[time,lati,loni] == 0\n",
    "            elif(time>0) :\n",
    "                if (xrain[time,lati,loni]<0) :\n",
    "                    xrain[time,lati,loni] = xrain[time-1,lati,loni]\n",
    "                if (xrain[time,lati,loni]-xrain[time-1,lati,loni]<0) :\n",
    "                    xrain[time,lati,loni] = xrain[time-1,lati,loni]\n",
    "\n",
    "hjn = np.empty((len(dates),len(lat),len(lon)))\n",
    "hjn[0,:,:] = xrain[0,:,:]\n",
    "for i in range (1,len(dates)) :\n",
    "    hjn[i,:,:] = xrain[i,:,:]-xrain[i-1,:,:]\n",
    "\n",
    "hjn2 = hjn.reshape(len(dates), 1, len(lat), len(lon))\n",
    "\n",
    "ds = xr.open_dataset(local_file_path)\n",
    "ds['tp'].values = hjn2\n",
    "ds = ds.assign_coords(time=(\"time\",ds['time'].values + np.timedelta64(7,'h')))\n",
    "\n",
    "output_rewrite = f\"ECMWF_new.0125.{today.strftime('%Y%m%d')}{cycle}00.PREC.nc\"\n",
    "output_path = os.path.join(path_nc_row, output_rewrite)\n",
    "ds.to_netcdf(output_path)\n",
    "print (ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ECMWF_new_3d.0125.202503041200.PREC.nc berhasil dibuat\n",
      "{'lat': <class 'netCDF4.Variable'>\n",
      "float64 lat(lat)\n",
      "    grads_dim: y\n",
      "    grads_mapping: linear\n",
      "    grads_size: 185\n",
      "    units: degrees_north\n",
      "    long_name: latitude\n",
      "    minimum: -14.0\n",
      "    maximum: 9.0\n",
      "    resolution: -0.125\n",
      "unlimited dimensions: \n",
      "current shape = (185,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'lon': <class 'netCDF4.Variable'>\n",
      "float64 lon(lon)\n",
      "    grads_dim: x\n",
      "    grads_mapping: linear\n",
      "    grads_size: 449\n",
      "    units: degrees_east\n",
      "    long_name: longitude\n",
      "    minimum: 92.0\n",
      "    maximum: 148.0\n",
      "    resolution: 0.125\n",
      "unlimited dimensions: \n",
      "current shape = (449,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'lev': <class 'netCDF4.Variable'>\n",
      "float64 lev(lev)\n",
      "    grads_dim: z\n",
      "    grads_mapping: levels\n",
      "    units: millibar\n",
      "    long_name: altitude\n",
      "unlimited dimensions: \n",
      "current shape = (1,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'time': <class 'netCDF4.Variable'>\n",
      "float64 time(time)\n",
      "    grads_dim: t\n",
      "    grads_mapping: linear\n",
      "    grads_size: 65\n",
      "    units: hours since 2025-03-04 12:00:00\n",
      "    grads_step: 3hr\n",
      "    long_name: validity time\n",
      "unlimited dimensions: \n",
      "current shape = (65,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'tp': <class 'netCDF4.Variable'>\n",
      "float64 tp(time, lev, lat, lon)\n",
      "    least_significant_digit: 3\n",
      "    longname: Precipitation Accumulation (mm)\n",
      "unlimited dimensions: \n",
      "current shape = (65, 1, 185, 449)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used}\n",
      "2025-03-04 12:00:00\n"
     ]
    }
   ],
   "source": [
    "result_file_name = f\"ECMWF_new_3d.0125.{today.strftime('%Y%m%d')}{cycle}00.PREC.nc\"\n",
    "\n",
    "file_path = os.path.join(path_modified, result_file_name)\n",
    "\n",
    "f = Dataset(file_path, 'w', format='NETCDF4')\n",
    "print(f\"File {result_file_name} berhasil dibuat\")\n",
    "print (data.variables)\n",
    "\n",
    "rain = hjn[:48,:,:]\n",
    "latitude = data.variables[\"lat\"][:]\n",
    "longitude = data.variables[\"lon\"][:]\n",
    "time_k = data.variables['time'][:48]\n",
    "\n",
    "tempgrp = f.createGroup('Rain_data')\n",
    "\n",
    "f.createDimension('lon', len(longitude))\n",
    "f.createDimension('lat', len(latitude))\n",
    "f.createDimension('time', len(time_k))\n",
    "\n",
    "lon = f.createVariable('lon', 'f4', 'lon')\n",
    "lat = f.createVariable('lat', 'f4', 'lat')  \n",
    "rain = f.createVariable('rain', 'f4', ('time', 'lat', 'lon'))\n",
    "time = f.createVariable('time', 'i4', 'time')\n",
    "\n",
    "lon[:] = longitude[:]\n",
    "lat[:] = latitude[:]\n",
    "rain[:,:,:] = hjn[:48,:,:]\n",
    "time[:] = time_k+7\n",
    "\n",
    "print (dates[0].strftime('%Y-%m-%d ')+str(cycle)+\":00:00\")\n",
    "\n",
    "f.description = \"ECMWF from BMKG modified by Jhon doe\"\n",
    "f.history = \"Created \" + today.strftime(\"%d/%m/%y\")\n",
    "\n",
    "lon.units = 'degree_east'\n",
    "lat.units = 'degree_north'\n",
    "time.units = 'hours since '+(dates[0]+datetime.timedelta(hours=7)).strftime('%Y-%m-%d ')+str(cycle)+\":00:00\"\n",
    "rain.units = 'mm'\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lon': <class 'netCDF4.Variable'>\n",
      "float32 lon(lon)\n",
      "    units: degree_east\n",
      "unlimited dimensions: \n",
      "current shape = (449,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'lat': <class 'netCDF4.Variable'>\n",
      "float32 lat(lat)\n",
      "    units: degree_north\n",
      "unlimited dimensions: \n",
      "current shape = (185,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'rain': <class 'netCDF4.Variable'>\n",
      "float32 rain(time, lat, lon)\n",
      "    units: mm\n",
      "unlimited dimensions: \n",
      "current shape = (48, 185, 449)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'time': <class 'netCDF4.Variable'>\n",
      "int32 time(time)\n",
      "    units: hours since 2025-03-04 12:00:00\n",
      "unlimited dimensions: \n",
      "current shape = (48,)\n",
      "filling on, default _FillValue of -2147483647 used}\n"
     ]
    }
   ],
   "source": [
    "data_path = f\"../repository/pre-processing/result-row\\ECMWF_new_3d.0125.{today.strftime('%Y%m%d')}{cycle}00.PREC.nc\"\n",
    "\n",
    "n = 0\n",
    "\n",
    "data = Dataset(data_path)\n",
    "print(data.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROSES UNTUK WMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-06 01:00:00 WIB\n",
      "2025-03-07 04:00:00 WIB\n",
      "Successfully convert 1D netCDF to tiff: ../repository/post-processing/nc_to_tiff/pch_day_03062025/pch_day_03062025.tif\n",
      "Successfully convert 3H netCDF to tiff: ../repository/post-processing/nc_to_tiff/pch_hour_03062025/pch_hour_03062025_0100_22.00.tif\n",
      "Successfully convert 3H netCDF to tiff: ../repository/post-processing/nc_to_tiff/pch_hour_03062025/pch_hour_03062025_0400_22.00.tif\n",
      "Successfully convert 3H netCDF to tiff: ../repository/post-processing/nc_to_tiff/pch_hour_03062025/pch_hour_03062025_0700_22.00.tif\n",
      "Successfully convert 3H netCDF to tiff: ../repository/post-processing/nc_to_tiff/pch_hour_03062025/pch_hour_03062025_1000_22.00.tif\n",
      "Successfully convert 3H netCDF to tiff: ../repository/post-processing/nc_to_tiff/pch_hour_03062025/pch_hour_03062025_1300_22.00.tif\n",
      "Successfully convert 3H netCDF to tiff: ../repository/post-processing/nc_to_tiff/pch_hour_03062025/pch_hour_03062025_1600_22.00.tif\n",
      "Successfully convert 3H netCDF to tiff: ../repository/post-processing/nc_to_tiff/pch_hour_03062025/pch_hour_03062025_1900_22.00.tif\n",
      "Successfully convert 3H netCDF to tiff: ../repository/post-processing/nc_to_tiff/pch_hour_03062025/pch_hour_03062025_2200_22.00.tif\n",
      "Result masked: ../repository/post-processing/wms/hour/pch_hour_03062025/pch_hour_03062025_0100_22.00.tif\n",
      "Result masked: ../repository/post-processing/wms/hour/pch_hour_03062025/pch_hour_03062025_0400_22.00.tif\n",
      "Result masked: ../repository/post-processing/wms/hour/pch_hour_03062025/pch_hour_03062025_0700_22.00.tif\n",
      "Result masked: ../repository/post-processing/wms/hour/pch_hour_03062025/pch_hour_03062025_1000_22.00.tif\n",
      "Result masked: ../repository/post-processing/wms/hour/pch_hour_03062025/pch_hour_03062025_1300_22.00.tif\n",
      "Result masked: ../repository/post-processing/wms/hour/pch_hour_03062025/pch_hour_03062025_1600_22.00.tif\n",
      "Result masked: ../repository/post-processing/wms/hour/pch_hour_03062025/pch_hour_03062025_1900_22.00.tif\n",
      "Result masked: ../repository/post-processing/wms/hour/pch_hour_03062025/pch_hour_03062025_2200_22.00.tif\n",
      "Result masked: ../repository/post-processing/wms/day/pch_day_03062025/pch_day_03062025.tif\n",
      "Successfully delete folder ../repository/post-processing/nc_to_tiff/pch_hour_03062025/\n",
      "Successfully delete folder ../repository/post-processing/nc_to_tiff/pch_day_03062025/\n"
     ]
    }
   ],
   "source": [
    "time = data.variables['time'][:]\n",
    "dates = num2date(time, data.variables['time'].units)\n",
    "print((dates[10+n]).strftime('%Y-%m-%d %H:%M:%S WIB'))\n",
    "print((dates[19+n]).strftime('%Y-%m-%d %H:%M:%S WIB'))\n",
    "\n",
    "lon_wms = np.array(data.variables[\"lon\"][:])\n",
    "lat_wms = np.array(data.variables[\"lat\"][:])\n",
    "prec_wms = np.array(data.variables[\"rain\"][:])\n",
    "\n",
    "xx, yy = np.meshgrid(lon_wms, lat_wms)\n",
    "accumulation = 0\n",
    "start_date = dates[11+n - 1].strftime('%m%d%Y')\n",
    "\n",
    "input_hour_dir = f\"../repository/post-processing/nc_to_tiff/pch_hour_{start_date}/\"\n",
    "input_day_dir = f\"../repository/post-processing/nc_to_tiff/pch_day_{start_date}/\"\n",
    "output_masked_hour_dir = f\"../repository/post-processing/wms/hour/pch_hour_{start_date}/\"\n",
    "output_masked_day_dir = f\"../repository/post-processing/wms/day/pch_day_{start_date}/\"\n",
    "\n",
    "os.makedirs(input_hour_dir, exist_ok=True)\n",
    "os.makedirs(input_day_dir, exist_ok=True)\n",
    "os.makedirs(output_masked_hour_dir, exist_ok=True)\n",
    "os.makedirs(output_masked_day_dir, exist_ok=True)\n",
    "\n",
    "accumulation=0\n",
    "\n",
    "for k in range(11+n, 19+n):\n",
    "    hour_data = prec_wms[k, :, :]\n",
    "    accumulation += hour_data\n",
    "\n",
    "np.max(accumulation)\n",
    "\n",
    "def classify_rainfall(data):\n",
    "    classified = np.zeros_like(data, dtype=np.uint8)  \n",
    "    classified[(data > 0.5) & (data <= 20)] = 1       \n",
    "    classified[(data > 20) & (data <= 50)] = 2        \n",
    "    classified[(data > 50) & (data <= 100)] = 3       \n",
    "    classified[(data > 100) & (data <= 150)] =4       \n",
    "    classified[data > 150] = 5                        \n",
    "    return classified\n",
    "\n",
    "classified_rain = classify_rainfall(accumulation)\n",
    "\n",
    "resolution_lon = (lon_wms.max() - lon_wms.min()) / lon_wms.shape[0]\n",
    "resolution_lat = (lat_wms.max() - lat_wms.min()) / lat_wms.shape[0]\n",
    "\n",
    "transform = from_origin(lon_wms.min(), lat_wms.max(), resolution_lon, resolution_lat)\n",
    "\n",
    "tiff_filename_hour = os.path.join(input_day_dir, f\"pch_day_{start_date}.tif\")\n",
    "\n",
    "with rasterio.open(\n",
    "    tiff_filename_hour,\n",
    "    'w',\n",
    "    driver='GTiff',\n",
    "    height=classified_rain.shape[0],\n",
    "    width=classified_rain.shape[1],\n",
    "    count=1,\n",
    "    dtype=classified_rain.dtype,\n",
    "    crs=rasterio.crs.CRS.from_proj4(\"+proj=longlat +datum=WGS84 +no_defs\"),\n",
    "    transform=transform\n",
    ") as dst:\n",
    "    dst.write(classified_rain, 1)\n",
    "print(f\"Successfully convert 1D netCDF to tiff: {tiff_filename_hour}\")\n",
    "\n",
    "def classify_rainfall3h(data):\n",
    "    classified = np.zeros_like(data, dtype=np.uint8)  \n",
    "    classified[(data > 1) & (data <= 5)] = 1            \n",
    "    classified[(data > 5) & (data <= 10)] = 2           \n",
    "    classified[(data > 10) & (data <= 20)] = 3          \n",
    "    classified[data > 20] = 4                           \n",
    "    return classified\n",
    "\n",
    "for k in range(11+n, 19+n):\n",
    "    hour_data = prec_wms[k, :, :]\n",
    "    \n",
    "    classified_rain3h = classify_rainfall3h(hour_data)\n",
    "    \n",
    "    start_hour = dates[k - 1].strftime('%H%M')\n",
    "    \n",
    "    resolution_lon = (lon_wms.max() - lon_wms.min()) / lon_wms.shape[0]\n",
    "    resolution_lat = (lat_wms.max() - lat_wms.min()) / lat_wms.shape[0]\n",
    "    transform = from_origin(lon_wms.min(), lat_wms.max(), resolution_lon, resolution_lat)\n",
    "\n",
    "    tiff_filename_hour = os.path.join(input_hour_dir, f\"pch_hour_{start_date}_{start_hour}_22.00.tif\")\n",
    "\n",
    "    with rasterio.open(\n",
    "        tiff_filename_hour,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=classified_rain3h.shape[0],\n",
    "        width=classified_rain3h.shape[1],\n",
    "        count=1,\n",
    "        dtype=classified_rain3h.dtype,\n",
    "        crs=rasterio.crs.CRS.from_proj4(\"+proj=longlat +datum=WGS84 +no_defs\"),\n",
    "        transform=transform\n",
    "    ) as dst:\n",
    "        dst.write(classified_rain3h, 1)\n",
    "\n",
    "    print(f\"Successfully convert 3H netCDF to tiff: {tiff_filename_hour}\")\n",
    "\n",
    "def masked_data(input_tiff, mask_file, output_masked_dir):\n",
    "    gdf = gpd.read_file(mask_file)\n",
    "    geometries = [geom for geom in gdf.geometry]\n",
    "\n",
    "    with rasterio.open(input_tiff) as src:\n",
    "        out_image, out_transform = mask(src, geometries, crop=True)\n",
    "        out_meta = src.meta.copy()\n",
    "\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": out_image.shape[1],\n",
    "        \"width\": out_image.shape[2],\n",
    "        \"transform\": out_transform\n",
    "    })\n",
    "\n",
    "    file_name = os.path.basename(input_tiff)\n",
    "    output_masked_tiff = os.path.join(output_masked_dir, file_name)\n",
    "\n",
    "    with rasterio.open(output_masked_tiff, \"w\", **out_meta) as dst:\n",
    "        dst.write(out_image)\n",
    "\n",
    "    print(f\"Result masked: {output_masked_tiff}\")\n",
    "\n",
    "for file in os.listdir(input_hour_dir):\n",
    "    if file.endswith(\".tif\"):\n",
    "        input_tiff = os.path.join(input_hour_dir, file)\n",
    "        masked_data(input_tiff, mask_pulau, output_masked_hour_dir)\n",
    "\n",
    "for file in os.listdir(input_day_dir):\n",
    "    if file.endswith(\".tif\"):\n",
    "        input_tiff = os.path.join(input_day_dir, file)\n",
    "        masked_data(input_tiff, mask_pulau, output_masked_day_dir)\n",
    "\n",
    "def delete_nc_to_tif(folder_path_for_tif):\n",
    "    try:\n",
    "        if os.path.exists(folder_path_for_tif):\n",
    "            shutil.rmtree(folder_path_for_tif)\n",
    "            print(f\"Successfully delete folder {folder_path_for_tif}\")\n",
    "        else:\n",
    "            print(f\"not found or previously deleted {folder_path_for_tif}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to delete folder {folder_path_for_tif}: {e}\")\n",
    "\n",
    "delete_nc_to_tif(input_hour_dir)\n",
    "delete_nc_to_tif(input_day_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROSES UNTUK WFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-06 01:00:00 WIB\n",
      "2025-03-06 19:00:00 WIB\n"
     ]
    }
   ],
   "source": [
    "time = data.variables['time'][:]\n",
    "dates = num2date(time, data.variables['time'].units)\n",
    "print((dates[10+n]).strftime('%Y-%m-%d %H:%M:%S WIB'))\n",
    "print((dates[16+n]).strftime('%Y-%m-%d %H:%M:%S WIB'))\n",
    "\n",
    "lat_wfs = data.variables[\"lat\"][:]\n",
    "lon_wfs = data.variables[\"lon\"][:]\n",
    "prec_wfs = data.variables['rain'][:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       lat_prod   long_prod  lat_data  long_data  idx_lat  idx_long  wilayah  \\\n",
      "0     -7.475905  111.498259    -7.500     110.50      132       148        2   \n",
      "1     -7.475905  111.498259    -7.500     110.50      132       148        2   \n",
      "2     -7.475905  111.498259    -7.750     110.75      134       150        2   \n",
      "3     -7.475905  111.498259    -7.750     110.75      134       150        2   \n",
      "4     -7.475905  111.498259    -7.750     110.50      134       148        2   \n",
      "...         ...         ...       ...        ...      ...       ...      ...   \n",
      "46990 -8.183800  113.727000    -8.125     123.75      137       254        2   \n",
      "46991 -8.183800  113.727000    -8.125     123.75      137       254        2   \n",
      "46992 -8.183800  113.727000    -8.125     123.75      137       254        2   \n",
      "46993 -8.183800  113.727000    -8.125     123.75      137       254        2   \n",
      "46994 -8.183800  113.727000    -8.125     123.75      137       254        2   \n",
      "\n",
      "                         wilayah_sungai  kode_balai               balai  \\\n",
      "0                      WS BENGAWAN SOLO         1.0  BBWS BENGAWAN SOLO   \n",
      "1                      WS BENGAWAN SOLO         1.0  BBWS BENGAWAN SOLO   \n",
      "2                      WS BENGAWAN SOLO         1.0  BBWS BENGAWAN SOLO   \n",
      "3                      WS BENGAWAN SOLO         1.0  BBWS BENGAWAN SOLO   \n",
      "4                      WS BENGAWAN SOLO         1.0  BBWS BENGAWAN SOLO   \n",
      "...                                 ...         ...                 ...   \n",
      "46990  WS FLOTIM KEPULAUAN-LEMBATA-ALOR       999.0           NON-B/BWS   \n",
      "46991  WS FLOTIM KEPULAUAN-LEMBATA-ALOR       999.0           NON-B/BWS   \n",
      "46992  WS FLOTIM KEPULAUAN-LEMBATA-ALOR       999.0           NON-B/BWS   \n",
      "46993  WS FLOTIM KEPULAUAN-LEMBATA-ALOR       999.0           NON-B/BWS   \n",
      "46994  WS FLOTIM KEPULAUAN-LEMBATA-ALOR       999.0           NON-B/BWS   \n",
      "\n",
      "                 das       pulau  kode_prov                    provinsi  \\\n",
      "0      BENGAWAN SOLO        JAWA         34  Daerah Istimewa Yogyakarta   \n",
      "1           OPAK-OYO        JAWA         34  Daerah Istimewa Yogyakarta   \n",
      "2      BENGAWAN SOLO        JAWA         34  Daerah Istimewa Yogyakarta   \n",
      "3           OPAK-OYO        JAWA         34  Daerah Istimewa Yogyakarta   \n",
      "4      BENGAWAN SOLO        JAWA         34  Daerah Istimewa Yogyakarta   \n",
      "...              ...         ...        ...                         ...   \n",
      "46990       SAGUWOWO  BALI & NTT         53         Nusa Tenggara Timur   \n",
      "46991           MI'I  BALI & NTT         53         Nusa Tenggara Timur   \n",
      "46992        PEUWUTU  BALI & NTT         53         Nusa Tenggara Timur   \n",
      "46993   BOTAN TILENG  BALI & NTT         53         Nusa Tenggara Timur   \n",
      "46994     BUA BARENG  BALI & NTT         53         Nusa Tenggara Timur   \n",
      "\n",
      "      kode_kabkot       kabkot  \n",
      "0           34.04       Sleman  \n",
      "1           34.04       Sleman  \n",
      "2           34.03  Gunungkidul  \n",
      "3           34.03  Gunungkidul  \n",
      "4           34.03  Gunungkidul  \n",
      "...           ...          ...  \n",
      "46990       53.13      Lembata  \n",
      "46991       53.13      Lembata  \n",
      "46992       53.13      Lembata  \n",
      "46993       53.13      Lembata  \n",
      "46994       53.13      Lembata  \n",
      "\n",
      "[46995 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max.columns\",None)\n",
    "grid = pd.read_excel(path_pch_tabular)\n",
    "print (grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46995"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_long = grid['idx_long'].to_numpy()\n",
    "grid_lat = grid['idx_lat'].to_numpy()\n",
    "longitude_r = grid['long_data']\n",
    "latitude_r = grid['lat_data']\n",
    "latitude_prod = grid['lat_prod']\n",
    "longitude_prod = grid['long_prod']\n",
    "pulau = grid['pulau']\n",
    "balai = grid['balai']\n",
    "kode_balai = grid['kode_balai']\n",
    "ws = grid ['wilayah_sungai']\n",
    "das = grid['das']\n",
    "prov = grid[\"provinsi\"]\n",
    "kota = grid['kabkot']\n",
    "wilayah = grid['wilayah']\n",
    "latshape = grid_lat.shape[0]\n",
    "latshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025030604\n",
      "2025030607\n",
      "2025030610\n",
      "2025030613\n",
      "2025030616\n",
      "2025030619\n",
      "2025030622\n",
      "2025030701\n"
     ]
    }
   ],
   "source": [
    "for k in range (11+n,19+n):\n",
    "    print((dates[k]).strftime(\"%Y%m%d%H\"))\n",
    "    idx_t=(dates[k]).strftime(\"%Y%m%d%H\")\n",
    "    if (k==19+n):\n",
    "        globals()['hujanharian_'+(idx_t)] = prec_wfs[11+n,:,:]\n",
    "    else:\n",
    "        globals()['hujanharian_'+(idx_t)] = prec_wfs[11+n:k+1,:,:].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025030704\n",
      "2025030707\n",
      "2025030710\n",
      "2025030713\n",
      "2025030716\n",
      "2025030719\n",
      "2025030722\n",
      "2025030801\n"
     ]
    }
   ],
   "source": [
    "for k in range (11+8+n,19+8+n):\n",
    "    print((dates[k]).strftime(\"%Y%m%d%H\"))\n",
    "    idx_t=(dates[k]).strftime(\"%Y%m%d%H\")\n",
    "    if (k==19+8+n):\n",
    "        globals()['hujanharian_'+(idx_t)] = prec_wfs[11+8+n,:,:]\n",
    "    else:\n",
    "        globals()['hujanharian_'+(idx_t)] = prec_wfs[11+8+n:k+1,:,:].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\830004694.py:52: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_dasWaspada = pd.concat([df_dasWaspada,df])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                long_prod  lat_prod  longitude  latitude       pulau  \\\n",
      "tanggal                                                                \n",
      "06 March 2025  111.498259 -7.475905    110.500    -7.500        JAWA   \n",
      "06 March 2025  102.365436 -3.519631    103.375    -4.375    SUMATERA   \n",
      "06 March 2025  102.365436 -3.519631    103.375    -4.375    SUMATERA   \n",
      "06 March 2025  102.365436 -3.519631    103.625    -4.500    SUMATERA   \n",
      "06 March 2025  102.365436 -3.519631    103.500    -4.500    SUMATERA   \n",
      "...                   ...       ...        ...       ...         ...   \n",
      "07 March 2025  115.132146 -8.369793    115.125    -8.750  BALI & NTT   \n",
      "07 March 2025  115.132146 -8.369793    115.125    -8.750  BALI & NTT   \n",
      "07 March 2025  115.132146 -8.369793    115.625    -8.875  BALI & NTT   \n",
      "07 March 2025  102.381755 -1.658707    101.500    -1.875    SUMATERA   \n",
      "07 March 2025  100.260480 -0.619902    101.000    -1.500    SUMATERA   \n",
      "\n",
      "               kode_balai               balai                 das  \\\n",
      "tanggal                                                             \n",
      "06 March 2025         1.0  BBWS BENGAWAN SOLO       BENGAWAN SOLO   \n",
      "06 March 2025        49.0    BWS SUMATERA VII         PADANG GUCI   \n",
      "06 March 2025        49.0    BWS SUMATERA VII                LUAS   \n",
      "06 March 2025        49.0    BWS SUMATERA VII                LUAS   \n",
      "06 March 2025        49.0    BWS SUMATERA VII                LUAS   \n",
      "...                   ...                 ...                 ...   \n",
      "07 March 2025        10.0     BWS BALI PENIDA      PANGKUNG TUBAN   \n",
      "07 March 2025        10.0     BWS BALI PENIDA        TUKAD BADUNG   \n",
      "07 March 2025        10.0     BWS BALI PENIDA  TUKAD SENGGUHUNGAN   \n",
      "07 March 2025        48.0     BWS SUMATERA VI          BATANGHARI   \n",
      "07 March 2025        47.0      BWS SUMATERA V             KAMBANG   \n",
      "\n",
      "                                 provinsi                     kabkot wilayah  \\\n",
      "tanggal                                                                        \n",
      "06 March 2025  Daerah Istimewa Yogyakarta                     Sleman       2   \n",
      "06 March 2025            Sumatera Selatan                 Muara Enim       1   \n",
      "06 March 2025            Sumatera Selatan  Ogan Komering Ulu Selatan       1   \n",
      "06 March 2025            Sumatera Selatan  Ogan Komering Ulu Selatan       1   \n",
      "06 March 2025            Sumatera Selatan  Ogan Komering Ulu Selatan       1   \n",
      "...                                   ...                        ...     ...   \n",
      "07 March 2025                        Bali                     Badung       2   \n",
      "07 March 2025                        Bali              Kota Denpasar       2   \n",
      "07 March 2025                        Bali                  Klungkung       2   \n",
      "07 March 2025                       Jambi                      Bungo       1   \n",
      "07 March 2025              Sumatera Barat            Pesisir Selatan       1   \n",
      "\n",
      "              waktu_mulai  ch_04:00  ch_07:00  ch_10:00   ch_13:00   ch_16:00  \\\n",
      "tanggal                                                                         \n",
      "06 March 2025       10:00  0.000000  0.078125  1.164062   4.085938   8.597656   \n",
      "06 March 2025       04:00  2.382812  2.832031  5.417969  11.308594  20.726562   \n",
      "06 March 2025       04:00  2.382812  2.832031  5.417969  11.308594  20.726562   \n",
      "06 March 2025       07:00  0.253906  2.632812  5.742188   5.863281   7.835938   \n",
      "06 March 2025       04:00  1.027344  3.234375  3.992188   4.066406   9.031250   \n",
      "...                   ...       ...       ...       ...        ...        ...   \n",
      "07 March 2025       10:00  0.339844  0.382812  0.757812   0.796875   0.882812   \n",
      "07 March 2025       10:00  0.339844  0.382812  0.757812   0.796875   0.882812   \n",
      "07 March 2025       13:00  0.203125  0.417969  0.445312   0.570312   0.945312   \n",
      "07 March 2025       13:00  0.000000  0.000000  0.027344   0.964844   2.160156   \n",
      "07 March 2025       16:00  0.000000  0.000000  0.074219   0.457031   1.160156   \n",
      "\n",
      "                ch_19:00   ch_22:00   ch_01:00 klasifikasi_hujan status_akhir  \n",
      "tanggal                                                                        \n",
      "06 March 2025   9.574219   9.574219   9.574219                 1            1  \n",
      "06 March 2025  22.687500  22.687500  22.722656                 2            1  \n",
      "06 March 2025  22.687500  22.687500  22.722656                 2            1  \n",
      "06 March 2025   8.324219   8.324219   8.324219                 1            1  \n",
      "06 March 2025  11.460938  11.460938  11.496094                 1            1  \n",
      "...                  ...        ...        ...               ...          ...  \n",
      "07 March 2025   1.726562   2.109375   2.484375                 1            1  \n",
      "07 March 2025   1.726562   2.109375   2.484375                 1            1  \n",
      "07 March 2025   1.085938   1.125000   1.164062                 1            1  \n",
      "07 March 2025   2.253906   2.261719   2.269531                 1            1  \n",
      "07 March 2025   1.285156   1.292969   1.332031                 1            1  \n",
      "\n",
      "[46579 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "kolom = ['long_prod', 'lat_prod', 'tanggal', 'longitude','latitude','pulau', 'kode_balai', 'balai','das','provinsi','kabkot','wilayah']\n",
    "df_dasWaspada = pd.DataFrame(columns=kolom)\n",
    "for tab in range (latshape) :\n",
    "    gridlat = grid_lat[tab]\n",
    "    gridlon = grid_long[tab]\n",
    "    for k in range (11+n,27+n):\n",
    "        idx_t = (dates[k]).strftime(\"%Y%m%d%H\")\n",
    "        idx_h = (dates[k]).strftime(\"%H:00\")\n",
    "        hujan_cek = globals()['hujanharian_'+(idx_t)]\n",
    "        \n",
    "        i_idx = 11+n if k<19+n else 19+n\n",
    "        tanggal = (dates[i_idx]).strftime(\"%d %B %Y\")\n",
    "        \n",
    "        if (hujan_cek[gridlat,gridlon]>=0.5):\n",
    "            df = pd.DataFrame([{'tanggal':tanggal, 'long_prod':longitude_prod[tab], 'lat_prod':latitude_prod[tab], 'longitude':longitude_r[tab],'latitude':latitude_r[tab], 'pulau':pulau[tab], 'kode_balai':kode_balai[tab], 'balai':balai[tab],\\\n",
    "                             'das':das[tab],'provinsi':prov[tab],'kabkot':kota[tab],'wilayah':wilayah[tab]\\\n",
    "                              ,'waktu_mulai':idx_h}])\n",
    "            i_idx = (11+n) if k<(19+n) else (19+n)\n",
    "            for i in range (i_idx,i_idx+8):\n",
    "                idx_t = (dates[i]).strftime(\"%Y%m%d%H\")\n",
    "                idx_h = (dates[i]).strftime(\"%H:00\")\n",
    "                df['ch_'+idx_h] = globals()['hujanharian_'+(idx_t)][gridlat,gridlon]\n",
    "            \n",
    "            kelas=globals()['hujanharian_'+(idx_t)][gridlat,gridlon]\n",
    "            if (0.5<kelas<=20):\n",
    "                status=\"1\" #HUJAN RINGAN\n",
    "            elif(20<kelas<=50):\n",
    "                status=\"2\" #HUJAN SEDANG\n",
    "            elif(50<kelas<=100):\n",
    "                status=\"3\" #HUJAN LEBAT\n",
    "            elif(100<kelas<=150):\n",
    "                status=\"4\" #HUJAN SANGAT LEBAT\n",
    "            elif(kelas>150):\n",
    "                status=\"5\" #HUJAN EKSTREM\n",
    "                \n",
    "            df[\"klasifikasi_hujan\"] = status\n",
    "            \n",
    "            status_cek = globals()['hujanharian_'+(idx_t)][gridlat,gridlon]\n",
    "            if (0.5<status_cek<=50):\n",
    "                status_1=\"1\" #AMAN\n",
    "            elif(50<status_cek<=75):\n",
    "                status_1=\"2\" #WASPADA\n",
    "            elif(75<status_cek<=100):\n",
    "                status_1=\"3\" #SIAGA\n",
    "            elif(status_cek>100):\n",
    "                status_1=\"4\" #AWAS\n",
    "            \n",
    "            df[\"status_akhir\"] = status_1\n",
    "            \n",
    "            df_dasWaspada = pd.concat([df_dasWaspada,df])\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "df = df_dasWaspada.sort_values(by=\"tanggal\")\n",
    "df = df.set_index(\"tanggal\")\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create accumulated data...\n",
      "Data accumulation has been completed...\n",
      "Read accumulation data...\n",
      "accumulation data value :\n",
      "             tanggal   long_prod  lat_prod  longitude  latitude       pulau  \\\n",
      "0      06 March 2025  111.498259 -7.475905    110.500    -7.500        JAWA   \n",
      "1      06 March 2025  102.365436 -3.519631    103.375    -4.375    SUMATERA   \n",
      "2      06 March 2025  102.365436 -3.519631    103.375    -4.375    SUMATERA   \n",
      "3      06 March 2025  102.365436 -3.519631    103.625    -4.500    SUMATERA   \n",
      "4      06 March 2025  102.365436 -3.519631    103.500    -4.500    SUMATERA   \n",
      "...              ...         ...       ...        ...       ...         ...   \n",
      "46574  07 March 2025  115.132146 -8.369793    115.125    -8.750  BALI & NTT   \n",
      "46575  07 March 2025  115.132146 -8.369793    115.125    -8.750  BALI & NTT   \n",
      "46576  07 March 2025  115.132146 -8.369793    115.625    -8.875  BALI & NTT   \n",
      "46577  07 March 2025  102.381755 -1.658707    101.500    -1.875    SUMATERA   \n",
      "46578  07 March 2025  100.260480 -0.619902    101.000    -1.500    SUMATERA   \n",
      "\n",
      "       kode_balai               balai                 das  \\\n",
      "0             1.0  BBWS BENGAWAN SOLO       BENGAWAN SOLO   \n",
      "1            49.0    BWS SUMATERA VII         PADANG GUCI   \n",
      "2            49.0    BWS SUMATERA VII                LUAS   \n",
      "3            49.0    BWS SUMATERA VII                LUAS   \n",
      "4            49.0    BWS SUMATERA VII                LUAS   \n",
      "...           ...                 ...                 ...   \n",
      "46574        10.0     BWS BALI PENIDA      PANGKUNG TUBAN   \n",
      "46575        10.0     BWS BALI PENIDA        TUKAD BADUNG   \n",
      "46576        10.0     BWS BALI PENIDA  TUKAD SENGGUHUNGAN   \n",
      "46577        48.0     BWS SUMATERA VI          BATANGHARI   \n",
      "46578        47.0      BWS SUMATERA V             KAMBANG   \n",
      "\n",
      "                         provinsi                     kabkot  wilayah  \\\n",
      "0      Daerah Istimewa Yogyakarta                     Sleman        2   \n",
      "1                Sumatera Selatan                 Muara Enim        1   \n",
      "2                Sumatera Selatan  Ogan Komering Ulu Selatan        1   \n",
      "3                Sumatera Selatan  Ogan Komering Ulu Selatan        1   \n",
      "4                Sumatera Selatan  Ogan Komering Ulu Selatan        1   \n",
      "...                           ...                        ...      ...   \n",
      "46574                        Bali                     Badung        2   \n",
      "46575                        Bali              Kota Denpasar        2   \n",
      "46576                        Bali                  Klungkung        2   \n",
      "46577                       Jambi                      Bungo        1   \n",
      "46578              Sumatera Barat            Pesisir Selatan        1   \n",
      "\n",
      "      waktu_mulai  ch_04:00  ch_07:00  ch_10:00   ch_13:00   ch_16:00  \\\n",
      "0           10:00  0.000000  0.078125  1.164062   4.085938   8.597656   \n",
      "1           04:00  2.382812  2.832031  5.417969  11.308594  20.726562   \n",
      "2           04:00  2.382812  2.832031  5.417969  11.308594  20.726562   \n",
      "3           07:00  0.253906  2.632812  5.742188   5.863281   7.835938   \n",
      "4           04:00  1.027344  3.234375  3.992188   4.066406   9.031250   \n",
      "...           ...       ...       ...       ...        ...        ...   \n",
      "46574       10:00  0.339844  0.382812  0.757812   0.796875   0.882812   \n",
      "46575       10:00  0.339844  0.382812  0.757812   0.796875   0.882812   \n",
      "46576       13:00  0.203125  0.417969  0.445312   0.570312   0.945312   \n",
      "46577       13:00  0.000000  0.000000  0.027344   0.964844   2.160156   \n",
      "46578       16:00  0.000000  0.000000  0.074219   0.457031   1.160156   \n",
      "\n",
      "        ch_19:00   ch_22:00   ch_01:00  klasifikasi_hujan  status_akhir  \n",
      "0       9.574219   9.574219   9.574219                  1             1  \n",
      "1      22.687500  22.687500  22.722656                  2             1  \n",
      "2      22.687500  22.687500  22.722656                  2             1  \n",
      "3       8.324219   8.324219   8.324219                  1             1  \n",
      "4      11.460938  11.460938  11.496094                  1             1  \n",
      "...          ...        ...        ...                ...           ...  \n",
      "46574   1.726562   2.109375   2.484375                  1             1  \n",
      "46575   1.726562   2.109375   2.484375                  1             1  \n",
      "46576   1.085938   1.125000   1.164062                  1             1  \n",
      "46577   2.253906   2.261719   2.269531                  1             1  \n",
      "46578   1.285156   1.292969   1.332031                  1             1  \n",
      "\n",
      "[46579 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print('Create accumulated data...')\n",
    "\n",
    "writer = pd.ExcelWriter('../repository/pre-processing/accumulation/accum_'+\\\n",
    "                        (dates[11+n]).strftime('%m%d%Y')+'_'\n",
    "                        +(dates[26+n]).strftime('%m%d%Y')+'.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Akumulasi Berjalan')\n",
    "writer.close()\n",
    "\n",
    "print('Data accumulation has been completed...')\n",
    "\n",
    "print('Read accumulation data...')\n",
    "data = pd.read_excel(\n",
    "    f\"../repository/pre-processing/accumulation/accum_{(dates[11+n]).strftime('%m%d%Y')}_{(dates[26+n]).strftime('%m%d%Y')}.xlsx\"\n",
    ")\n",
    "print(\"accumulation data value :\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomorrow's date: 06 March 2025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>long_prod</th>\n",
       "      <th>lat_prod</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>pulau</th>\n",
       "      <th>kode_balai</th>\n",
       "      <th>balai</th>\n",
       "      <th>das</th>\n",
       "      <th>provinsi</th>\n",
       "      <th>kabkot</th>\n",
       "      <th>wilayah</th>\n",
       "      <th>waktu_mulai</th>\n",
       "      <th>ch_04:00</th>\n",
       "      <th>ch_07:00</th>\n",
       "      <th>ch_10:00</th>\n",
       "      <th>ch_13:00</th>\n",
       "      <th>ch_16:00</th>\n",
       "      <th>ch_19:00</th>\n",
       "      <th>ch_22:00</th>\n",
       "      <th>ch_01:00</th>\n",
       "      <th>klasifikasi_hujan</th>\n",
       "      <th>status_akhir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>111.498259</td>\n",
       "      <td>-7.475905</td>\n",
       "      <td>110.500</td>\n",
       "      <td>-7.500</td>\n",
       "      <td>JAWA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BBWS BENGAWAN SOLO</td>\n",
       "      <td>BENGAWAN SOLO</td>\n",
       "      <td>Daerah Istimewa Yogyakarta</td>\n",
       "      <td>Sleman</td>\n",
       "      <td>2</td>\n",
       "      <td>10:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>1.164062</td>\n",
       "      <td>4.085938</td>\n",
       "      <td>8.597656</td>\n",
       "      <td>9.574219</td>\n",
       "      <td>9.574219</td>\n",
       "      <td>9.574219</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>102.365436</td>\n",
       "      <td>-3.519631</td>\n",
       "      <td>103.375</td>\n",
       "      <td>-4.375</td>\n",
       "      <td>SUMATERA</td>\n",
       "      <td>49.0</td>\n",
       "      <td>BWS SUMATERA VII</td>\n",
       "      <td>PADANG GUCI</td>\n",
       "      <td>Sumatera Selatan</td>\n",
       "      <td>Muara Enim</td>\n",
       "      <td>1</td>\n",
       "      <td>04:00</td>\n",
       "      <td>2.382812</td>\n",
       "      <td>2.832031</td>\n",
       "      <td>5.417969</td>\n",
       "      <td>11.308594</td>\n",
       "      <td>20.726562</td>\n",
       "      <td>22.687500</td>\n",
       "      <td>22.687500</td>\n",
       "      <td>22.722656</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>102.365436</td>\n",
       "      <td>-3.519631</td>\n",
       "      <td>103.375</td>\n",
       "      <td>-4.375</td>\n",
       "      <td>SUMATERA</td>\n",
       "      <td>49.0</td>\n",
       "      <td>BWS SUMATERA VII</td>\n",
       "      <td>LUAS</td>\n",
       "      <td>Sumatera Selatan</td>\n",
       "      <td>Ogan Komering Ulu Selatan</td>\n",
       "      <td>1</td>\n",
       "      <td>04:00</td>\n",
       "      <td>2.382812</td>\n",
       "      <td>2.832031</td>\n",
       "      <td>5.417969</td>\n",
       "      <td>11.308594</td>\n",
       "      <td>20.726562</td>\n",
       "      <td>22.687500</td>\n",
       "      <td>22.687500</td>\n",
       "      <td>22.722656</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>102.365436</td>\n",
       "      <td>-3.519631</td>\n",
       "      <td>103.625</td>\n",
       "      <td>-4.500</td>\n",
       "      <td>SUMATERA</td>\n",
       "      <td>49.0</td>\n",
       "      <td>BWS SUMATERA VII</td>\n",
       "      <td>LUAS</td>\n",
       "      <td>Sumatera Selatan</td>\n",
       "      <td>Ogan Komering Ulu Selatan</td>\n",
       "      <td>1</td>\n",
       "      <td>07:00</td>\n",
       "      <td>0.253906</td>\n",
       "      <td>2.632812</td>\n",
       "      <td>5.742188</td>\n",
       "      <td>5.863281</td>\n",
       "      <td>7.835938</td>\n",
       "      <td>8.324219</td>\n",
       "      <td>8.324219</td>\n",
       "      <td>8.324219</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>102.365436</td>\n",
       "      <td>-3.519631</td>\n",
       "      <td>103.500</td>\n",
       "      <td>-4.500</td>\n",
       "      <td>SUMATERA</td>\n",
       "      <td>49.0</td>\n",
       "      <td>BWS SUMATERA VII</td>\n",
       "      <td>LUAS</td>\n",
       "      <td>Sumatera Selatan</td>\n",
       "      <td>Ogan Komering Ulu Selatan</td>\n",
       "      <td>1</td>\n",
       "      <td>04:00</td>\n",
       "      <td>1.027344</td>\n",
       "      <td>3.234375</td>\n",
       "      <td>3.992188</td>\n",
       "      <td>4.066406</td>\n",
       "      <td>9.031250</td>\n",
       "      <td>11.460938</td>\n",
       "      <td>11.460938</td>\n",
       "      <td>11.496094</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45501</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>116.854937</td>\n",
       "      <td>3.014629</td>\n",
       "      <td>118.000</td>\n",
       "      <td>2.375</td>\n",
       "      <td>KALIMANTAN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>BWS KALIMANTAN V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kalimantan Utara</td>\n",
       "      <td>Bulungan</td>\n",
       "      <td>1</td>\n",
       "      <td>04:00</td>\n",
       "      <td>3.347656</td>\n",
       "      <td>3.464844</td>\n",
       "      <td>3.632812</td>\n",
       "      <td>4.304688</td>\n",
       "      <td>5.152344</td>\n",
       "      <td>7.980469</td>\n",
       "      <td>8.070312</td>\n",
       "      <td>8.480469</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45502</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>115.956516</td>\n",
       "      <td>0.275581</td>\n",
       "      <td>115.125</td>\n",
       "      <td>1.875</td>\n",
       "      <td>KALIMANTAN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>BWS KALIMANTAN IV</td>\n",
       "      <td>KAYAN</td>\n",
       "      <td>Kalimantan Utara</td>\n",
       "      <td>Malinau</td>\n",
       "      <td>1</td>\n",
       "      <td>10:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.949219</td>\n",
       "      <td>15.699219</td>\n",
       "      <td>17.367188</td>\n",
       "      <td>19.601562</td>\n",
       "      <td>21.640625</td>\n",
       "      <td>21.828125</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45503</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>116.854937</td>\n",
       "      <td>3.014629</td>\n",
       "      <td>117.750</td>\n",
       "      <td>2.500</td>\n",
       "      <td>KALIMANTAN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>BWS KALIMANTAN V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kalimantan Utara</td>\n",
       "      <td>Bulungan</td>\n",
       "      <td>1</td>\n",
       "      <td>04:00</td>\n",
       "      <td>3.210938</td>\n",
       "      <td>3.261719</td>\n",
       "      <td>3.710938</td>\n",
       "      <td>10.093750</td>\n",
       "      <td>20.398438</td>\n",
       "      <td>21.996094</td>\n",
       "      <td>21.996094</td>\n",
       "      <td>22.007812</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45504</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>116.854937</td>\n",
       "      <td>3.014629</td>\n",
       "      <td>117.625</td>\n",
       "      <td>2.500</td>\n",
       "      <td>KALIMANTAN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>BWS KALIMANTAN V</td>\n",
       "      <td>KAYAN</td>\n",
       "      <td>Kalimantan Utara</td>\n",
       "      <td>Bulungan</td>\n",
       "      <td>1</td>\n",
       "      <td>04:00</td>\n",
       "      <td>1.359375</td>\n",
       "      <td>1.433594</td>\n",
       "      <td>1.917969</td>\n",
       "      <td>2.828125</td>\n",
       "      <td>15.683594</td>\n",
       "      <td>15.992188</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.082031</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45505</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>116.854937</td>\n",
       "      <td>3.014629</td>\n",
       "      <td>116.750</td>\n",
       "      <td>3.125</td>\n",
       "      <td>KALIMANTAN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>BWS KALIMANTAN V</td>\n",
       "      <td>SESAYAP</td>\n",
       "      <td>Kalimantan Utara</td>\n",
       "      <td>Bulungan</td>\n",
       "      <td>1</td>\n",
       "      <td>10:00</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>5.761719</td>\n",
       "      <td>16.019531</td>\n",
       "      <td>17.324219</td>\n",
       "      <td>17.421875</td>\n",
       "      <td>20.378906</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45506 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tanggal   long_prod  lat_prod  longitude  latitude       pulau  \\\n",
       "0      06 March 2025  111.498259 -7.475905    110.500    -7.500        JAWA   \n",
       "1      06 March 2025  102.365436 -3.519631    103.375    -4.375    SUMATERA   \n",
       "2      06 March 2025  102.365436 -3.519631    103.375    -4.375    SUMATERA   \n",
       "3      06 March 2025  102.365436 -3.519631    103.625    -4.500    SUMATERA   \n",
       "4      06 March 2025  102.365436 -3.519631    103.500    -4.500    SUMATERA   \n",
       "...              ...         ...       ...        ...       ...         ...   \n",
       "45501  06 March 2025  116.854937  3.014629    118.000     2.375  KALIMANTAN   \n",
       "45502  06 March 2025  115.956516  0.275581    115.125     1.875  KALIMANTAN   \n",
       "45503  06 March 2025  116.854937  3.014629    117.750     2.500  KALIMANTAN   \n",
       "45504  06 March 2025  116.854937  3.014629    117.625     2.500  KALIMANTAN   \n",
       "45505  06 March 2025  116.854937  3.014629    116.750     3.125  KALIMANTAN   \n",
       "\n",
       "       kode_balai               balai            das  \\\n",
       "0             1.0  BBWS BENGAWAN SOLO  BENGAWAN SOLO   \n",
       "1            49.0    BWS SUMATERA VII    PADANG GUCI   \n",
       "2            49.0    BWS SUMATERA VII           LUAS   \n",
       "3            49.0    BWS SUMATERA VII           LUAS   \n",
       "4            49.0    BWS SUMATERA VII           LUAS   \n",
       "...           ...                 ...            ...   \n",
       "45501        53.0    BWS KALIMANTAN V            NaN   \n",
       "45502        52.0   BWS KALIMANTAN IV          KAYAN   \n",
       "45503        53.0    BWS KALIMANTAN V            NaN   \n",
       "45504        53.0    BWS KALIMANTAN V          KAYAN   \n",
       "45505        53.0    BWS KALIMANTAN V        SESAYAP   \n",
       "\n",
       "                         provinsi                     kabkot  wilayah  \\\n",
       "0      Daerah Istimewa Yogyakarta                     Sleman        2   \n",
       "1                Sumatera Selatan                 Muara Enim        1   \n",
       "2                Sumatera Selatan  Ogan Komering Ulu Selatan        1   \n",
       "3                Sumatera Selatan  Ogan Komering Ulu Selatan        1   \n",
       "4                Sumatera Selatan  Ogan Komering Ulu Selatan        1   \n",
       "...                           ...                        ...      ...   \n",
       "45501            Kalimantan Utara                   Bulungan        1   \n",
       "45502            Kalimantan Utara                    Malinau        1   \n",
       "45503            Kalimantan Utara                   Bulungan        1   \n",
       "45504            Kalimantan Utara                   Bulungan        1   \n",
       "45505            Kalimantan Utara                   Bulungan        1   \n",
       "\n",
       "      waktu_mulai  ch_04:00  ch_07:00  ch_10:00   ch_13:00   ch_16:00  \\\n",
       "0           10:00  0.000000  0.078125  1.164062   4.085938   8.597656   \n",
       "1           04:00  2.382812  2.832031  5.417969  11.308594  20.726562   \n",
       "2           04:00  2.382812  2.832031  5.417969  11.308594  20.726562   \n",
       "3           07:00  0.253906  2.632812  5.742188   5.863281   7.835938   \n",
       "4           04:00  1.027344  3.234375  3.992188   4.066406   9.031250   \n",
       "...           ...       ...       ...       ...        ...        ...   \n",
       "45501       04:00  3.347656  3.464844  3.632812   4.304688   5.152344   \n",
       "45502       10:00  0.000000  0.000000  5.949219  15.699219  17.367188   \n",
       "45503       04:00  3.210938  3.261719  3.710938  10.093750  20.398438   \n",
       "45504       04:00  1.359375  1.433594  1.917969   2.828125  15.683594   \n",
       "45505       10:00  0.003906  0.027344  0.531250   5.761719  16.019531   \n",
       "\n",
       "        ch_19:00   ch_22:00   ch_01:00  klasifikasi_hujan  status_akhir  \n",
       "0       9.574219   9.574219   9.574219                  1             1  \n",
       "1      22.687500  22.687500  22.722656                  2             1  \n",
       "2      22.687500  22.687500  22.722656                  2             1  \n",
       "3       8.324219   8.324219   8.324219                  1             1  \n",
       "4      11.460938  11.460938  11.496094                  1             1  \n",
       "...          ...        ...        ...                ...           ...  \n",
       "45501   7.980469   8.070312   8.480469                  1             1  \n",
       "45502  19.601562  21.640625  21.828125                  2             1  \n",
       "45503  21.996094  21.996094  22.007812                  2             1  \n",
       "45504  15.992188  16.000000  16.082031                  1             1  \n",
       "45505  17.324219  17.421875  20.378906                  2             1  \n",
       "\n",
       "[45506 rows x 23 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "tanggal_hari_ini = datetime.now()\n",
    "tanggal_besok = tanggal_hari_ini + timedelta(days=1)\n",
    "\n",
    "tanggal_besok_str = tanggal_besok.strftime(\"%d %B %Y\")\n",
    "print(\"Tomorrow's date:\", tanggal_besok_str)\n",
    "\n",
    "data_tanggal_besok = data[data['tanggal'] == tanggal_besok_str]\n",
    "data_tanggal_besok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result sorting descanding: 06 March 2025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tanggal</th>\n",
       "      <th>long_prod</th>\n",
       "      <th>lat_prod</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>pulau</th>\n",
       "      <th>kode_balai</th>\n",
       "      <th>balai</th>\n",
       "      <th>das</th>\n",
       "      <th>provinsi</th>\n",
       "      <th>kabkot</th>\n",
       "      <th>wilayah</th>\n",
       "      <th>waktu_mulai</th>\n",
       "      <th>ch_04:00</th>\n",
       "      <th>ch_07:00</th>\n",
       "      <th>ch_10:00</th>\n",
       "      <th>ch_13:00</th>\n",
       "      <th>ch_16:00</th>\n",
       "      <th>ch_19:00</th>\n",
       "      <th>ch_22:00</th>\n",
       "      <th>ch_01:00</th>\n",
       "      <th>klasifikasi_hujan</th>\n",
       "      <th>status_akhir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40723</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>114.792207</td>\n",
       "      <td>-1.317482</td>\n",
       "      <td>115.250</td>\n",
       "      <td>-2.125</td>\n",
       "      <td>KALIMANTAN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>BWS KALIMANTAN III</td>\n",
       "      <td>BARITO</td>\n",
       "      <td>Kalimantan Tengah</td>\n",
       "      <td>Barito Timur</td>\n",
       "      <td>1</td>\n",
       "      <td>10:00</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>1.738281</td>\n",
       "      <td>4.050781</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>13.976562</td>\n",
       "      <td>28.156250</td>\n",
       "      <td>93.375000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42737</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>114.792207</td>\n",
       "      <td>-1.317482</td>\n",
       "      <td>115.250</td>\n",
       "      <td>-2.125</td>\n",
       "      <td>KALIMANTAN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>BWS KALIMANTAN III</td>\n",
       "      <td>BARITO</td>\n",
       "      <td>Kalimantan Selatan</td>\n",
       "      <td>Tabalong</td>\n",
       "      <td>1</td>\n",
       "      <td>10:00</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>1.738281</td>\n",
       "      <td>4.050781</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>13.976562</td>\n",
       "      <td>28.156250</td>\n",
       "      <td>93.375000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40753</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>114.792207</td>\n",
       "      <td>-1.317482</td>\n",
       "      <td>115.250</td>\n",
       "      <td>-2.250</td>\n",
       "      <td>KALIMANTAN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>BWS KALIMANTAN III</td>\n",
       "      <td>BARITO</td>\n",
       "      <td>Kalimantan Tengah</td>\n",
       "      <td>Barito Timur</td>\n",
       "      <td>1</td>\n",
       "      <td>13:00</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>3.449219</td>\n",
       "      <td>8.726562</td>\n",
       "      <td>16.585938</td>\n",
       "      <td>30.390625</td>\n",
       "      <td>81.871094</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42742</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>114.792207</td>\n",
       "      <td>-1.317482</td>\n",
       "      <td>115.250</td>\n",
       "      <td>-2.250</td>\n",
       "      <td>KALIMANTAN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>BWS KALIMANTAN III</td>\n",
       "      <td>BARITO</td>\n",
       "      <td>Kalimantan Selatan</td>\n",
       "      <td>Tabalong</td>\n",
       "      <td>1</td>\n",
       "      <td>13:00</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>3.449219</td>\n",
       "      <td>8.726562</td>\n",
       "      <td>16.585938</td>\n",
       "      <td>30.390625</td>\n",
       "      <td>81.871094</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42886</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>114.792207</td>\n",
       "      <td>-1.317482</td>\n",
       "      <td>114.875</td>\n",
       "      <td>-2.750</td>\n",
       "      <td>KALIMANTAN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>BWS KALIMANTAN III</td>\n",
       "      <td>BARITO</td>\n",
       "      <td>Kalimantan Selatan</td>\n",
       "      <td>Tapin</td>\n",
       "      <td>1</td>\n",
       "      <td>10:00</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>3.660156</td>\n",
       "      <td>3.941406</td>\n",
       "      <td>6.796875</td>\n",
       "      <td>19.562500</td>\n",
       "      <td>31.511719</td>\n",
       "      <td>74.417969</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>113.727000</td>\n",
       "      <td>-8.183800</td>\n",
       "      <td>100.875</td>\n",
       "      <td>-1.875</td>\n",
       "      <td>SUMATERA</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NON-B/BWS</td>\n",
       "      <td>PUNGGASAN</td>\n",
       "      <td>Sumatera Barat</td>\n",
       "      <td>Pesisir Selatan</td>\n",
       "      <td>1</td>\n",
       "      <td>19:00</td>\n",
       "      <td>0.417969</td>\n",
       "      <td>0.417969</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5038</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>113.727000</td>\n",
       "      <td>-8.183800</td>\n",
       "      <td>100.875</td>\n",
       "      <td>-1.875</td>\n",
       "      <td>SUMATERA</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NON-B/BWS</td>\n",
       "      <td>PELANGAI</td>\n",
       "      <td>Sumatera Barat</td>\n",
       "      <td>Pesisir Selatan</td>\n",
       "      <td>1</td>\n",
       "      <td>19:00</td>\n",
       "      <td>0.417969</td>\n",
       "      <td>0.417969</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5037</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>113.727000</td>\n",
       "      <td>-8.183800</td>\n",
       "      <td>100.875</td>\n",
       "      <td>-1.875</td>\n",
       "      <td>SUMATERA</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NON-B/BWS</td>\n",
       "      <td>INDRAPURA</td>\n",
       "      <td>Sumatera Barat</td>\n",
       "      <td>Pesisir Selatan</td>\n",
       "      <td>1</td>\n",
       "      <td>19:00</td>\n",
       "      <td>0.417969</td>\n",
       "      <td>0.417969</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5036</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>113.727000</td>\n",
       "      <td>-8.183800</td>\n",
       "      <td>100.875</td>\n",
       "      <td>-1.875</td>\n",
       "      <td>SUMATERA</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NON-B/BWS</td>\n",
       "      <td>AIR HAJI</td>\n",
       "      <td>Sumatera Barat</td>\n",
       "      <td>Pesisir Selatan</td>\n",
       "      <td>1</td>\n",
       "      <td>19:00</td>\n",
       "      <td>0.417969</td>\n",
       "      <td>0.417969</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2669</th>\n",
       "      <td>06 March 2025</td>\n",
       "      <td>105.406016</td>\n",
       "      <td>1.479285</td>\n",
       "      <td>104.625</td>\n",
       "      <td>1.250</td>\n",
       "      <td>SUMATERA</td>\n",
       "      <td>33.0</td>\n",
       "      <td>BWS SUMATERA IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kepulauan Riau</td>\n",
       "      <td>Bintan</td>\n",
       "      <td>1</td>\n",
       "      <td>16:00</td>\n",
       "      <td>0.121094</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.269531</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45506 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tanggal   long_prod  lat_prod  longitude  latitude       pulau  \\\n",
       "40723  06 March 2025  114.792207 -1.317482    115.250    -2.125  KALIMANTAN   \n",
       "42737  06 March 2025  114.792207 -1.317482    115.250    -2.125  KALIMANTAN   \n",
       "40753  06 March 2025  114.792207 -1.317482    115.250    -2.250  KALIMANTAN   \n",
       "42742  06 March 2025  114.792207 -1.317482    115.250    -2.250  KALIMANTAN   \n",
       "42886  06 March 2025  114.792207 -1.317482    114.875    -2.750  KALIMANTAN   \n",
       "...              ...         ...       ...        ...       ...         ...   \n",
       "5039   06 March 2025  113.727000 -8.183800    100.875    -1.875    SUMATERA   \n",
       "5038   06 March 2025  113.727000 -8.183800    100.875    -1.875    SUMATERA   \n",
       "5037   06 March 2025  113.727000 -8.183800    100.875    -1.875    SUMATERA   \n",
       "5036   06 March 2025  113.727000 -8.183800    100.875    -1.875    SUMATERA   \n",
       "2669   06 March 2025  105.406016  1.479285    104.625     1.250    SUMATERA   \n",
       "\n",
       "       kode_balai               balai        das            provinsi  \\\n",
       "40723        11.0  BWS KALIMANTAN III     BARITO   Kalimantan Tengah   \n",
       "42737        11.0  BWS KALIMANTAN III     BARITO  Kalimantan Selatan   \n",
       "40753        11.0  BWS KALIMANTAN III     BARITO   Kalimantan Tengah   \n",
       "42742        11.0  BWS KALIMANTAN III     BARITO  Kalimantan Selatan   \n",
       "42886        11.0  BWS KALIMANTAN III     BARITO  Kalimantan Selatan   \n",
       "...           ...                 ...        ...                 ...   \n",
       "5039        999.0           NON-B/BWS  PUNGGASAN      Sumatera Barat   \n",
       "5038        999.0           NON-B/BWS   PELANGAI      Sumatera Barat   \n",
       "5037        999.0           NON-B/BWS  INDRAPURA      Sumatera Barat   \n",
       "5036        999.0           NON-B/BWS   AIR HAJI      Sumatera Barat   \n",
       "2669         33.0     BWS SUMATERA IV        NaN      Kepulauan Riau   \n",
       "\n",
       "                kabkot  wilayah waktu_mulai  ch_04:00  ch_07:00  ch_10:00  \\\n",
       "40723     Barito Timur        1       10:00  0.085938  0.109375  1.738281   \n",
       "42737         Tabalong        1       10:00  0.085938  0.109375  1.738281   \n",
       "40753     Barito Timur        1       13:00  0.015625  0.039062  0.421875   \n",
       "42742         Tabalong        1       13:00  0.015625  0.039062  0.421875   \n",
       "42886            Tapin        1       10:00  0.164062  0.246094  3.660156   \n",
       "...                ...      ...         ...       ...       ...       ...   \n",
       "5039   Pesisir Selatan        1       19:00  0.417969  0.417969  0.496094   \n",
       "5038   Pesisir Selatan        1       19:00  0.417969  0.417969  0.496094   \n",
       "5037   Pesisir Selatan        1       19:00  0.417969  0.417969  0.496094   \n",
       "5036   Pesisir Selatan        1       19:00  0.417969  0.417969  0.496094   \n",
       "2669            Bintan        1       16:00  0.121094  0.246094  0.269531   \n",
       "\n",
       "       ch_13:00  ch_16:00   ch_19:00   ch_22:00   ch_01:00  klasifikasi_hujan  \\\n",
       "40723  4.050781  7.500000  13.976562  28.156250  93.375000                  3   \n",
       "42737  4.050781  7.500000  13.976562  28.156250  93.375000                  3   \n",
       "40753  3.449219  8.726562  16.585938  30.390625  81.871094                  3   \n",
       "42742  3.449219  8.726562  16.585938  30.390625  81.871094                  3   \n",
       "42886  3.941406  6.796875  19.562500  31.511719  74.417969                  3   \n",
       "...         ...       ...        ...        ...        ...                ...   \n",
       "5039   0.496094  0.496094   0.500000   0.500000   0.500000                  1   \n",
       "5038   0.496094  0.496094   0.500000   0.500000   0.500000                  1   \n",
       "5037   0.496094  0.496094   0.500000   0.500000   0.500000                  1   \n",
       "5036   0.496094  0.496094   0.500000   0.500000   0.500000                  1   \n",
       "2669   0.281250  0.500000   0.500000   0.500000   0.500000                  1   \n",
       "\n",
       "       status_akhir  \n",
       "40723             3  \n",
       "42737             3  \n",
       "40753             3  \n",
       "42742             3  \n",
       "42886             2  \n",
       "...             ...  \n",
       "5039              1  \n",
       "5038              1  \n",
       "5037              1  \n",
       "5036              1  \n",
       "2669              1  \n",
       "\n",
       "[45506 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Result sorting descanding:\", tanggal_besok_str)\n",
    "data_tanggal_besok_sorted = data_tanggal_besok.sort_values(by='ch_01:00', ascending=False)\n",
    "data_tanggal_besok_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create tabular data for remdup_balai...\n",
      "Tabular data for remdup_balai has been completed and saved\n",
      "klasifikasi_hujan                1    2   3\n",
      "balai                                      \n",
      "BBWS BENGAWAN SOLO              17   11   0\n",
      "BBWS BRANTAS                    10   13   0\n",
      "BBWS CIDANAU-CIUJUNG-CIDURIAN    5    2   0\n",
      "BBWS CILIWUNG-CISADANE          12    5   0\n",
      "BBWS CIMANUK-CISANGGARUNG        5    8   0\n",
      "BBWS CITANDUY                   10    1   0\n",
      "BBWS CITARUM                     5    9   0\n",
      "BBWS MESUJI SEKAMPUNG            8    9   0\n",
      "BBWS NT I                       11    0   0\n",
      "BBWS NT II                      14    0   0\n",
      "BBWS PEMALI JUANA                9    7   0\n",
      "BBWS POMPENGAN JENEBERANG        3   26   5\n",
      "BBWS SERAYU OPAK                 9   16   0\n",
      "BBWS SUMATERA II                11    9   0\n",
      "BBWS SUMATERA VIII              18   16   0\n",
      "BWS BALI PENIDA                  9    0   0\n",
      "BWS BANGKA BELITUNG              2    4   0\n",
      "BWS KALIMANTAN I                 0   17   1\n",
      "BWS KALIMANTAN II                0   15   2\n",
      "BWS KALIMANTAN III               0   14  10\n",
      "BWS KALIMANTAN IV                0   11   2\n",
      "BWS KALIMANTAN V                 1    6   0\n",
      "BWS MALUKU                       6    0   0\n",
      "BWS MALUKU UTARA                 3    5   0\n",
      "BWS PAPUA                        2   15   9\n",
      "BWS PAPUA BARAT                  2   16   0\n",
      "BWS PAPUA MERAUKE                5    7   1\n",
      "BWS SULAWESI I                  12    5   0\n",
      "BWS SULAWESI II                  7    5   0\n",
      "BWS SULAWESI III                 0    9   2\n",
      "BWS SULAWESI IV                  1    9   0\n",
      "BWS SULAWESI V                   0    7   4\n",
      "BWS SUMATERA I                  12   14   0\n",
      "BWS SUMATERA III                17    5   0\n",
      "BWS SUMATERA IV                  6    1   0\n",
      "BWS SUMATERA V                  30    0   0\n",
      "BWS SUMATERA VI                 14    3   0\n",
      "BWS SUMATERA VII                 7    7   0\n",
      "NON-B/BWS                      118  113  11\n",
      "Create tabular data for remdup_pulau...\n",
      "Tabular data for remdup_pulau has been completed and saved\n",
      "klasifikasi_hujan   1   2   3\n",
      "pulau                        \n",
      "BALI & NTT         39   0   0\n",
      "JAWA               61  54   4\n",
      "KALIMANTAN          1  42  13\n",
      "MALUKU             14   7   0\n",
      "PAPUA               2  30  10\n",
      "SULAWESI           27  47   9\n",
      "SUMATERA           75  76   2\n"
     ]
    }
   ],
   "source": [
    "def create_remove_duplicate_tabular_data(data, subset_columns, output_folder, file_prefix, index_column):\n",
    "    print(f'Create tabular data for {file_prefix}...')\n",
    "\n",
    "    data_filtered = data.drop_duplicates(subset=subset_columns, keep='first')\n",
    "\n",
    "    remove_duplicate_tabular_data_path = os.path.join(output_folder, f\"{file_prefix}_{(dates[11+n]).strftime('%m%d%Y')}.xlsx\")\n",
    "\n",
    "    with pd.ExcelWriter(remove_duplicate_tabular_data_path, engine='xlsxwriter') as writer:\n",
    "        data_filtered.to_excel(writer, sheet_name=file_prefix.capitalize())\n",
    "\n",
    "    print(f'Tabular data for {file_prefix} has been completed and saved')\n",
    "\n",
    "    pivot = pd.pivot_table(\n",
    "        data_filtered,\n",
    "        index=index_column,\n",
    "        columns='klasifikasi_hujan',\n",
    "        values='kabkot',\n",
    "        aggfunc='count',\n",
    "        fill_value=0\n",
    "    )\n",
    "\n",
    "    print(pivot)\n",
    "\n",
    "create_remove_duplicate_tabular_data(\n",
    "    data=data_tanggal_besok_sorted,\n",
    "    subset_columns=['balai', 'kabkot'],\n",
    "    output_folder=\"../repository/pre-processing/remove-duplicate/balai/\",\n",
    "    file_prefix=\"remdup_balai\",\n",
    "    index_column=\"balai\"\n",
    ")\n",
    "\n",
    "create_remove_duplicate_tabular_data(\n",
    "    data=data_tanggal_besok_sorted,\n",
    "    subset_columns=['kabkot'],\n",
    "    output_folder=\"../repository/pre-processing/remove-duplicate/pulau/\",\n",
    "    file_prefix=\"remdup_pulau\",\n",
    "    index_column=\"pulau\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for balai_pch_day...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing for balai_pch_day completed\n",
      "Processing data for pulau_pch_day...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n",
      "C:\\Users\\2ndba\\AppData\\Local\\Temp\\ipykernel_11452\\364751837.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_data_filtered[col] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing for pulau_pch_day completed\n"
     ]
    }
   ],
   "source": [
    "def prediction_data(remove_duplicate_path, get_columns, group_by, output_prediction, uniq_file_name):\n",
    "    print(f'Processing data for {uniq_file_name}...')\n",
    "\n",
    "    data_for_prediction = pd.read_excel(remove_duplicate_path)\n",
    "    prediction_data_filtered = data_for_prediction[get_columns]\n",
    "\n",
    "    add_columns = [\n",
    "        'total_kl_1', 'total_kl_2', 'total_kl_3', 'total_kl_4', 'total_kl_5',\n",
    "        'total_kg_1', 'total_kg_2', 'total_kg_3', 'total_kg_4',\n",
    "        'kelas_kl_1', 'kelas_kl_2', 'kelas_kl_3', 'kelas_kl_4', 'kelas_kl_5',\n",
    "        'kelas_kg_1', 'kelas_kg_2', 'kelas_kg_3', 'kelas_kg_4',\n",
    "        'last_data', 'last_updt'\n",
    "    ]\n",
    "\n",
    "    for col in add_columns:\n",
    "        prediction_data_filtered[col] = 0\n",
    "\n",
    "    for wilayah in prediction_data_filtered['wilayah'].unique():\n",
    "        wilayah_data = prediction_data_filtered[prediction_data_filtered['wilayah'] == wilayah]\n",
    "        for i in range(1, 6): \n",
    "            prediction_data_filtered.loc[prediction_data_filtered['wilayah'] == wilayah, f'total_kl_{i}'] = wilayah_data[wilayah_data['klasifikasi_hujan'] == i].shape[0]\n",
    "\n",
    "    for wilayah in prediction_data_filtered['wilayah'].unique():\n",
    "        wilayah_data = prediction_data_filtered[prediction_data_filtered['wilayah'] == wilayah]\n",
    "        for i in range(1, 5): \n",
    "            prediction_data_filtered.loc[prediction_data_filtered['wilayah'] == wilayah, f'total_kg_{i}'] = wilayah_data[wilayah_data['status_akhir'] == i].shape[0]\n",
    "\n",
    "    for group in prediction_data_filtered[group_by].unique():\n",
    "        group_data = prediction_data_filtered[prediction_data_filtered[group_by] == group]\n",
    "        for i in range(1, 6): \n",
    "            prediction_data_filtered.loc[prediction_data_filtered[group_by] == group, f'kelas_kl_{i}'] = group_data[group_data['klasifikasi_hujan'] == i].shape[0]\n",
    "\n",
    "    for group in prediction_data_filtered[group_by].unique():\n",
    "        group_data = prediction_data_filtered[prediction_data_filtered[group_by] == group]\n",
    "        for i in range(1, 5): \n",
    "            prediction_data_filtered.loc[prediction_data_filtered[group_by] == group, f'kelas_kg_{i}'] = group_data[group_data['status_akhir'] == i].shape[0]\n",
    "\n",
    "    prediction_data_filtered['last_data'] = filename\n",
    "    prediction_data_filtered['last_updt'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    prediction_data_filtered = prediction_data_filtered.drop_duplicates(subset=[group_by])\n",
    "\n",
    "    output_file = os.path.join(output_prediction, f\"{uniq_file_name}_{(dates[11+n]).strftime('%m%d%Y')}_2200.csv\")\n",
    "\n",
    "    prediction_data_filtered.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f'Data processing for {uniq_file_name} completed')\n",
    "\n",
    "\n",
    "prediction_data(\n",
    "    remove_duplicate_path=f\"../repository/pre-processing/remove-duplicate/balai/remdup_balai_{(dates[11+n]).strftime('%m%d%Y')}.xlsx\",\n",
    "    get_columns=[\n",
    "        'tanggal', 'long_prod', 'lat_prod', 'longitude', 'latitude', 'wilayah', 'kode_balai', 'balai', 'ch_01:00',\n",
    "        'klasifikasi_hujan', 'status_akhir'\n",
    "    ],\n",
    "    group_by=\"balai\",\n",
    "    output_prediction=\"../repository/processing/day/balai/\",\n",
    "    uniq_file_name=\"balai_pch_day\"\n",
    ")\n",
    "\n",
    "prediction_data(\n",
    "    remove_duplicate_path=f\"../repository/pre-processing/remove-duplicate/pulau/remdup_pulau_{(dates[11+n]).strftime('%m%d%Y')}.xlsx\",\n",
    "    get_columns=[\n",
    "        'tanggal', 'long_prod', 'lat_prod', 'longitude', 'latitude', 'wilayah', 'pulau', 'ch_01:00',\n",
    "        'klasifikasi_hujan', 'status_akhir'\n",
    "    ],\n",
    "    group_by=\"pulau\",\n",
    "    output_prediction=\"../repository/processing/day/pulau/\",\n",
    "    uniq_file_name=\"pulau_pch_day\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created vektor data ../repository/post-processing/wfs/balai/pch_balai_03062025/balai_pch_day_03062025_2200.shp\n",
      "Successfully created vektor data ../repository/post-processing/wfs/pulau/pch_pulau_03062025/pulau_pch_day_03062025_2200.shp\n"
     ]
    }
   ],
   "source": [
    "def csv_to_shp(csv_file, output_wfs_dir, output_shp):\n",
    "\n",
    "    os.makedirs(output_wfs_dir, exist_ok=True)\n",
    "\n",
    "    data = pd.read_csv(csv_file)\n",
    "\n",
    "    columns_to_drop = ['ch_01:00', 'klasifikasi_hujan', 'status_akhir']\n",
    "    data = data.drop(columns=[col for col in columns_to_drop if col in data.columns], errors='ignore')\n",
    "\n",
    "    if 'latitude' in data.columns and 'longitude' in data.columns:\n",
    "        data['geometry'] = data.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)\n",
    "\n",
    "        gdf = gpd.GeoDataFrame(data, geometry='geometry')\n",
    "        gdf.set_crs(epsg=4326, inplace=True)\n",
    "        gdf.to_file(output_shp, driver='ESRI Shapefile')\n",
    "\n",
    "        print(f\"Successfully created vektor data {output_shp}\")\n",
    "    else:\n",
    "        print(\"Column 'latitude' or 'longitude' was not found in the CSV file\")\n",
    "\n",
    "start_date = (dates[11+n]).strftime('%m%d%Y')\n",
    "\n",
    "output_balai_dir = f\"../repository/post-processing/wfs/balai/pch_balai_{start_date}/\"\n",
    "output_pulau_dir = f\"../repository/post-processing/wfs/pulau/pch_pulau_{start_date}/\"\n",
    "\n",
    "csv_to_shp(\n",
    "    csv_file=f\"../repository/processing/day/balai/balai_pch_day_{start_date}_2200.csv\",\n",
    "    output_wfs_dir=output_balai_dir,\n",
    "    output_shp=f\"{output_balai_dir}balai_pch_day_{start_date}_2200.shp\"\n",
    ")\n",
    "\n",
    "csv_to_shp(\n",
    "    csv_file=f\"../repository/processing/day/pulau/pulau_pch_day_{start_date}_2200.csv\",\n",
    "    output_wfs_dir=output_pulau_dir,\n",
    "    output_shp=f\"{output_pulau_dir}pulau_pch_day_{start_date}_2200.shp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded ../repository/post-processing/wfs/balai/pch_balai_03062025/balai_pch_day_03062025_2200.shp to geoserver\n",
      "Successfully uploaded ../repository/post-processing/wfs/pulau/pch_pulau_03062025/pulau_pch_day_03062025_2200.shp to geoserver\n",
      "Successfully uploaded ../repository/post-processing/wms/day/pch_day_03062025/pch_day_03062025.tif to geoserver\n",
      "Successfully uploaded ../repository/post-processing/wms/hour/pch_hour_03062025/pch_hour_03062025_0100_22.00.tif to geoserver\n",
      "Successfully uploaded ../repository/post-processing/wms/hour/pch_hour_03062025/pch_hour_03062025_0400_22.00.tif to geoserver\n",
      "Successfully uploaded ../repository/post-processing/wms/hour/pch_hour_03062025/pch_hour_03062025_0700_22.00.tif to geoserver\n",
      "Successfully uploaded ../repository/post-processing/wms/hour/pch_hour_03062025/pch_hour_03062025_1000_22.00.tif to geoserver\n",
      "Successfully uploaded ../repository/post-processing/wms/hour/pch_hour_03062025/pch_hour_03062025_1300_22.00.tif to geoserver\n",
      "Successfully uploaded ../repository/post-processing/wms/hour/pch_hour_03062025/pch_hour_03062025_1600_22.00.tif to geoserver\n",
      "Successfully uploaded ../repository/post-processing/wms/hour/pch_hour_03062025/pch_hour_03062025_1900_22.00.tif to geoserver\n",
      "Successfully uploaded ../repository/post-processing/wms/hour/pch_hour_03062025/pch_hour_03062025_2200_22.00.tif to geoserver\n"
     ]
    }
   ],
   "source": [
    "shp_dirs = [f\"../repository/post-processing/wfs/balai/pch_balai_{start_date}/\", f\"../repository/post-processing/wfs/pulau/pch_pulau_{start_date}/\"]\n",
    "tif_dirs = [f\"../repository/post-processing/wms/day/pch_day_{start_date}/\", f\"../repository/post-processing/wms/hour/pch_hour_{start_date}/\"]\n",
    "geoserver_endpoint = \"http://admin:geoserver@127.0.0.1:8080/geoserver\"\n",
    "workspace = \"demo_simadu\"\n",
    "\n",
    "def upload_to_geoserver(data_path, store_name, geoserver_endpoint, workspace):\n",
    "    file_extension = os.path.splitext(data_path)[1].lower()\n",
    "    if file_extension == \".shp\":\n",
    "        file_type = \"shp\"\n",
    "        store_type = \"datastores\"\n",
    "    elif file_extension == \".tif\":\n",
    "        file_type = \"geotiff\"\n",
    "        store_type = \"coveragestores\"\n",
    "    else:\n",
    "        print(f\"File type {file_extension} not supported for upload.\")\n",
    "        return False\n",
    "\n",
    "    absolute_path = os.path.abspath(data_path).replace(\"\\\\\", \"/\")\n",
    "    url = f\"{geoserver_endpoint}/rest/workspaces/{workspace}/{store_type}/{store_name}/external.{file_type}\"\n",
    "\n",
    "    headers = {\"Content-type\": \"text/plain\"}\n",
    "    response = requests.put(url, data=f\"file://{absolute_path}\", headers=headers, auth=(\"admin\", \"geoserver\"))\n",
    "\n",
    "    if response.status_code in [200, 201]:\n",
    "        print(f\"Successfully uploaded {data_path} to geoserver\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Failed to upload {data_path} to geoserver. Status code: {response.status_code}\")\n",
    "        return False\n",
    "\n",
    "def process_and_upload_to_geoserver(shp_dirs, tif_dirs, geoserver_endpoint, workspace):\n",
    "    for shp_dir in shp_dirs:\n",
    "        shp_files = [os.path.join(shp_dir, file) for file in os.listdir(shp_dir) if file.endswith('.shp')]\n",
    "        for shp_file in shp_files:\n",
    "            store_name = os.path.splitext(os.path.basename(shp_file))[0]\n",
    "            upload_to_geoserver(shp_file, store_name, geoserver_endpoint, workspace)\n",
    "\n",
    "    for tif_dir in tif_dirs:\n",
    "        tif_files = [os.path.join(tif_dir, file) for file in os.listdir(tif_dir) if file.endswith('.tif')]\n",
    "        for tif_file in tif_files:\n",
    "            store_name = os.path.splitext(os.path.basename(tif_file))[0]\n",
    "            upload_to_geoserver(tif_file, store_name, geoserver_endpoint, workspace)\n",
    "\n",
    "process_and_upload_to_geoserver(\n",
    "    shp_dirs,\n",
    "    tif_dirs,\n",
    "    geoserver_endpoint,\n",
    "    workspace,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
